{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mirai-udpplain' 'BenignTraffic' 'DNS_Spoofing' 'MITM-ArpSpoofing'\n",
      " 'Recon-OSScan' 'DDoS-ICMP_Fragmentation']\n",
      "Index(['flow_duration', 'Header_Length', 'Protocol Type', 'Duration', 'Rate',\n",
      "       'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
      "       'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
      "       'ece_flag_number', 'cwr_flag_number', 'ack_count', 'syn_count',\n",
      "       'fin_count', 'urg_count', 'rst_count', 'HTTP', 'HTTPS', 'DNS', 'Telnet',\n",
      "       'SMTP', 'SSH', 'IRC', 'TCP', 'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC',\n",
      "       'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number',\n",
      "       'Magnitude', 'Radius', 'Covariance', 'Variance', 'Weight', 'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# df = pd.read_csv(\"data\\part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\")\n",
    "df = pd.read_csv(\"data/part-00001-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\")\n",
    "df.rename(columns={'Magnitue': 'Magnitude'}, inplace=True)\n",
    "\n",
    "# selected_labels = [\n",
    "#     'BenignTraffic', 'BrowserHijacking', 'CommandInjection',\n",
    "#     'DDoS-ICMP_Fragmentation', 'DNS_Spoofing', 'MITM-ArpSpoofing',\n",
    "#     'Recon-OSScan', 'VulnerabilityScan'\n",
    "# ]\n",
    "\n",
    "selected_labels = [\n",
    "    # 'BenignTraffic', 'DDoS-ICMP_Fragmentation', 'DNS_Spoofing', 'MITM-ArpSpoofing', 'Recon-OSScan', 'VulnerabilityScan'\n",
    "    'BenignTraffic', 'DDoS-ICMP_Fragmentation', 'DNS_Spoofing', 'MITM-ArpSpoofing', 'Recon-OSScan', 'Mirai-udpplain'\n",
    "]\n",
    "df = df[df['label'].isin(selected_labels)]\n",
    "print(df['label'].unique())\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# Benign Traffic, Browser Hijacking, Command injection, DDoS-ICMP_Fragmentation, DNS Spoofing, MITM-ArpSpoofing, Recon-OSScan, Vulnerability scan.\n",
    "# Benign Traffic, Command injection, DDoS-ICMP_Fragmentation, DNS Spoofing, MITM-ArpSpoofing, Recon-OSScan, Vulnerability scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only 'label' and 'Magnitude' columns\n",
    "selected_data = df[['label', 'Magnitude']]\n",
    "\n",
    "# Group by 'label' and aggregate 'Magnitude' values into a list\n",
    "grouped_data = selected_data.groupby('label')['Magnitude'].agg(list).reset_index()\n",
    "\n",
    "# Save the selected data to a JSON file\n",
    "grouped_data.to_json('JSON/boxplot_data.json', orient='records', lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'label' and convert each group to a list\n",
    "grouped_data = df.groupby('label')['Duration'].apply(list)\n",
    "\n",
    "# Convert the grouped data to a list of dictionaries\n",
    "data = [{'label': label, 'Duration': durations} for label, durations in grouped_data.items()]\n",
    "\n",
    "# Write the Python object to a file\n",
    "with open('JSON/violin-plot_Duration_data.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Duration', 'Tot size', 'label']\n",
    "grouped_data = df[selected_columns]\n",
    "\n",
    "# Group by 'label' and aggregate 'Duration' and 'Tot size' values into a list\n",
    "selected_data = grouped_data.groupby('label').agg(list).reset_index()\n",
    "\n",
    "# Keep only the first 10 values for 'Duration' and 'Protocol Type' for every label\n",
    "selected_data['Duration'] = selected_data['Duration'].apply(lambda x: x[:20])\n",
    "selected_data['Tot size'] = selected_data['Tot size'].apply(lambda x: x[:20])\n",
    "\n",
    "# Convert DataFrame to JSON string\n",
    "json_str = selected_data.to_json(orient='records')\n",
    "\n",
    "# Parse JSON string to Python object\n",
    "data = json.loads(json_str)\n",
    "\n",
    "# Write pretty-printed JSON to file\n",
    "with open('JSON/scatter-plot_Size_data.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Columns with Highest Numeric Variance (excluding 'IAT' and 'Tot sum'):\n",
      "Header_Length, Covariance, Rate, Srate, Max, rst_count, flow_duration, Radius, Tot size, AVG\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Select numerical columns\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Remove \"IAT\" and \"Tot sum\" from the list of numerical columns\n",
    "numerical_cols = [col for col in numerical_cols if col not in [\"IAT\", \"Tot sum\"]]\n",
    "\n",
    "# Step 2: Calculate variance for each numerical column (excluding \"IAT\") and select the top 10\n",
    "top_variance_cols = df[numerical_cols].var().nlargest(10).index.tolist()\n",
    "\n",
    "# Step 3: Print the top 10 columns with the highest numeric variance\n",
    "print(\"Top 10 Columns with Highest Numeric Variance (excluding 'IAT' and 'Tot sum'):\")\n",
    "print(\", \".join(top_variance_cols))\n",
    "\n",
    "# Save the normalized data to a JSON file\n",
    "df[top_variance_cols].to_json(\"JSON/spider-plot_normalized_data.json\", orient=\"index\", indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_columns = ['label', 'Rate', 'Duration']\n",
    "# grouped_data = df[selected_columns]\n",
    "\n",
    "# # Group by 'label' and aggregate 'Duration' and 'Rate' values into lists\n",
    "# selected_data = grouped_data.groupby('label').agg(list).reset_index()\n",
    "\n",
    "# # Adjust 'Rate' values based on thresholds\n",
    "# selected_data['Rate'] = selected_data['Rate'].apply(lambda x: [val / 10 if val > 100 else val for val in x])\n",
    "# selected_data['Rate'] = selected_data['Rate'].apply(lambda x: [val / 100 if val > 1000 else val for val in x])\n",
    "\n",
    "# # Ensure 'Rate' values are not greater than 200\n",
    "# selected_data['Rate'] = selected_data['Rate'].apply(lambda x: [min(val, 200) for val in x])\n",
    "\n",
    "# # Reduce the number of values for 'Duration' and 'Rate' for every label\n",
    "# selected_data['Duration'] = selected_data['Duration'].apply(lambda x: x[:15])\n",
    "# selected_data['Rate'] = selected_data['Rate'].apply(lambda x: x[:15])\n",
    "\n",
    "# # Sort the values of the columns in ascending order\n",
    "# selected_data['Duration'] = sorted(selected_data['Duration'])\n",
    "# selected_data['Rate'] = sorted(selected_data['Rate'])\n",
    "\n",
    "# # Convert DataFrame to JSON string\n",
    "# json_str = selected_data.to_json(orient='records')\n",
    "\n",
    "# # Parse JSON string to Python object\n",
    "# data = json.loads(json_str)\n",
    "\n",
    "# # Write pretty-printed JSON to file\n",
    "# with open('JSON/line_plot_data.json', 'w') as f:\n",
    "#     json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_value(x):\n",
    "    while x > 999:\n",
    "        x /= 10\n",
    "    return x\n",
    "\n",
    "selected_columns = ['label', 'Header_Length', 'Duration']\n",
    "grouped_data = df[selected_columns]\n",
    "\n",
    "# Group by 'label' and aggregate 'Duration' and 'Header_Length' values into lists\n",
    "selected_data = grouped_data.groupby('label').agg(list).reset_index()\n",
    "\n",
    "# Reduce the number of values for 'Duration' and 'Header_Length' for every label\n",
    "selected_data['Duration'] = selected_data['Duration'].apply(lambda x: [normalize_value(i) for i in x[:15]])\n",
    "selected_data['Header_Length'] = selected_data['Header_Length'].apply(lambda x: [normalize_value(i) for i in x[:15]])\n",
    "\n",
    "# Sort the values of 'Duration' and 'Header_Length' columns in ascending order\n",
    "selected_data['Duration'] = selected_data['Duration'].apply(lambda x: sorted(x))\n",
    "selected_data['Header_Length'] = selected_data['Header_Length'].apply(lambda x: sorted(x))\n",
    "\n",
    "# Convert DataFrame to a list of dictionaries\n",
    "records = selected_data.to_dict(orient='records')\n",
    "\n",
    "# Convert the list of dictionaries to JSON\n",
    "json_str = json.dumps(records, indent=4)\n",
    "\n",
    "# Write pretty-printed JSON to file\n",
    "with open('JSON/line_plot_data.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
